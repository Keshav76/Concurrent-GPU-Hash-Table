Read Research Paper
 -> Concurrent Data Structures
 -> In CPU / GPU
 -> Hashing (Various Hash Functions)
 -> Hash Tables in C++/C
 -> Possible concurrency bugs when implementing a data structure in parallel environment
Graphs To plot
 -> Time vs No of Accesses
 -> Different Hashing Types
 -> Horizontal vs Vertical
Programming Language : CUDA
Team Split: (4 main operations) 2-2
 -> Create
 -> Read
 -> Update
 -> Delete




Roadmap:

1. CRUD Operations
2. Different Hashing Techniques (Cuckoo, etc)
3. Different CUDA implementations (Thrust, etc)

1. Different Test cases
2. Further corrections if needed
3. Have a baseline model

1. Improvements in performance and efficiency
2. Graphs: No of insertion/deletion per time -> Throughput -> Load Factor -> Latency Analysis -> 
3. Try some




Tools for Benchmarking:
1. CUDA Profiler (Nsight Compute / Nsight Systems)
2. Thrust library for parallel operations
3. Custom kernels with CUDA Events for timing 