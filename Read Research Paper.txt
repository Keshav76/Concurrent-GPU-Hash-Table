Read Research Paper
 -> Concurrent Data Structures
 -> In CPU / GPU
 -> Hashing (Various Hash Functions)
 -> Hash Tables in C++/C
 -> Possible concurrency bugs when implementing a data structure in parallel environment

Graphs To plot
 -> Time vs No of Accesses
 -> Different Hashing Types
 -> Horizontal vs Vertical

Programming Language : CUDA
Team Split: (4 main operations) 2-2
 -> Create
 -> Read
 -> Update
 -> Delete




Roadmap:

1. CRUD Operations
2. Have a baseline model (+ Some test cases)
3. Further corrections if needed
4. Different Test cases
5. Improvements in performance and efficiency
  1. Different Hashing Techniques (Cuckoo, etc)
  2. Different CUDA implementations (Thrust, etc)
  3. Graphs: No of insertion/deletion per time -> Throughput -> Load Factor -> Latency Analysis


2nd Review: 1, 2, 4
3rd Review: 3, 5, 4


Tools for Benchmarking:
1. CUDA Profiler (Nsight Compute / Nsight Systems)
2. Thrust library for parallel operations
3. Custom kernels with CUDA Events for timing 
